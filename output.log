ModelsManager.setup_update: models=dict_keys(['glaive-coder_7b', 'WizardCoder_13b', 'WizardCoder_33b', 'MagiCoder_7b', 'deepseek_coder_inst_6_7b', 'deepseek_coder_inst_1_3b', 'airophin_13b', 'Llama2_chat_13b', 'OpenOrca_7b', 'zephyr_a_7b', 'zephyr_b_7b', 'hermes_mistral_7b', 'dolphin_7b', 'intel_7b', 'orca_2_13b', 'phi_2_3b', 'solar_11b', 'openAI_gpt_4_turbo', 'openAI_gpt_4', 'openAI_gpt_3_5_turbo', 'Mistral_API_Medium'])
      Actions list: dict_keys(['Q_and_A', 'free', 'free_OpenAI', 'summarize', 'summarize_OpenAI', 'search', 'split', 'code', 'code_OpenAI', 'code_Mistral_API', 'code_quality', 'project_requirements', 'team_manager', 'team_manager_speach_OpenAI', 'team_manager_121_OpenAI', 'ideation_coach_OpenAI'])
Actions types list: ['__action_generate__']
    Functions list: ['__function_load_file__', '__function_search__']
Running on local URL:  http://127.0.0.1:7860

To create a public link, set `share=True` in `launch()`.
ZZZZZZZZZ default model:openAI_gpt_4_turbo
['glaive-coder_7b', 'WizardCoder_13b', 'WizardCoder_33b', 'MagiCoder_7b', 'deepseek_coder_inst_6_7b', 'deepseek_coder_inst_1_3b', 'airophin_13b', 'Llama2_chat_13b', 'OpenOrca_7b', 'zephyr_a_7b', 'zephyr_b_7b', 'hermes_mistral_7b', 'dolphin_7b', 'intel_7b', 'orca_2_13b', 'phi_2_3b', 'solar_11b', 'openAI_gpt_4_turbo', 'openAI_gpt_4', 'openAI_gpt_3_5_turbo', 'Mistral_API_Medium']
ZZZZZZZZZ
Model changed during this sessio for action: ideation_coach_OpenAI to this model:openAI_gpt_4_turbo
Model changed during this sessio for action: ideation_coach_OpenAI to this model:Mistral_API_Medium
Action: ideation_coach_OpenAI, num Inputs: 1
Model Mistral_API_Medium not yet instantiated, instantiating it now
WARNING: Model mistral-medium not in known_models list, running blind de instanciating everything just in case
Mistral Embeding initialised with model_name: mistral-embed
Mistral encode() called with text: a light that dose not produce light
Traceback (most recent call last):
  File "/home/me/miniforge3/envs/ab311/lib/python3.11/site-packages/gradio/queueing.py", line 495, in call_prediction
    output = await route_utils.call_process_api(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/me/miniforge3/envs/ab311/lib/python3.11/site-packages/gradio/route_utils.py", line 232, in call_process_api
    output = await app.get_blocks().process_api(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/me/miniforge3/envs/ab311/lib/python3.11/site-packages/gradio/blocks.py", line 1561, in process_api
    result = await self.call_function(
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/me/miniforge3/envs/ab311/lib/python3.11/site-packages/gradio/blocks.py", line 1179, in call_function
    prediction = await anyio.to_thread.run_sync(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/me/miniforge3/envs/ab311/lib/python3.11/site-packages/anyio/to_thread.py", line 56, in run_sync
    return await get_async_backend().run_sync_in_worker_thread(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/me/miniforge3/envs/ab311/lib/python3.11/site-packages/anyio/_backends/_asyncio.py", line 2134, in run_sync_in_worker_thread
    return await future
           ^^^^^^^^^^^^
  File "/home/me/miniforge3/envs/ab311/lib/python3.11/site-packages/anyio/_backends/_asyncio.py", line 851, in run
    result = context.run(func, *args)
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/me/miniforge3/envs/ab311/lib/python3.11/site-packages/gradio/utils.py", line 678, in wrapper
    response = f(*args, **kwargs)
               ^^^^^^^^^^^^^^^^^^
  File "/home/me/Documents/github/agent_bean/agent_bean_interface.py", line 94, in run_action
    output = ''.join(agent.agent_action(action_name, [action_input]))
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/me/Documents/github/agent_bean/agent_bean/agent_bean.py", line 50, in agent_action
    resp = self.aa.perform_action(action_name, inputs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/me/Documents/github/agent_bean/agent_bean/agent_actions.py", line 41, in perform_action
    return(getattr(self, action_f_name)(action_params))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/me/Documents/github/agent_bean/agent_bean/agent_actions.py", line 101, in __action_generate__
    input_tokens     = self.mm.get_embeddings(model_name, inputs[0])
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/me/Documents/github/agent_bean/agent_bean/models_manager.py", line 205, in get_embeddings
    return self.active_embeddings[model_name].encode(text)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/me/Documents/github/agent_bean/agent_bean/mistral_model.py", line 24, in encode
    embeddings_response = self.client.embeddings(model=self.model_name,input=[text])
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/me/miniforge3/envs/ab311/lib/python3.11/site-packages/mistralai/client.py", line 217, in embeddings
    for response in singleton_response:
  File "/home/me/miniforge3/envs/ab311/lib/python3.11/site-packages/mistralai/client.py", line 90, in _request
    yield self._check_response(response)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/me/miniforge3/envs/ab311/lib/python3.11/site-packages/mistralai/client_base.py", line 89, in _check_response
    self._check_response_status_codes(response)
  File "/home/me/miniforge3/envs/ab311/lib/python3.11/site-packages/mistralai/client_base.py", line 76, in _check_response_status_codes
    raise MistralAPIException.from_response(
mistralai.exceptions.MistralAPIException: Cannot stream response. Status: 401
